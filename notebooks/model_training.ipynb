{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dzastin96/product-category-classifier/blob/main/notebooks/model_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ü§ñ Model Training & Evaluation\n",
        "### Author: Dzastin Januzi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Goal\n",
        "\n",
        "Build and evaluate a robust product category classification pipeline using multiple machine learning algorithms.  \n",
        "The objective is to identify the best-performing model and feature setup for deployment in e-commerce or inventory systems.\n",
        "\n",
        "We compare five classifiers:\n",
        "- Logistic Regression\n",
        "- Naive Bayes\n",
        "- Decision Tree\n",
        "- Random Forest\n",
        "- Support Vector Machine (SVM)\n",
        "\n",
        "Each model is evaluated under two feature configurations:\n",
        "- üìù `product_title` only (text-based)\n",
        "- üßÆ `product_title` + numeric features (`views_per_day`, `popularity_score`, `merchant_rating`)\n",
        "\n",
        "üìä Evaluation metrics:\n",
        "- Accuracy\n",
        "- Macro F1 Score\n",
        "- Weighted F1 Score\n",
        "- Classification Report"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üì• 1. Load Data\n",
        "\n",
        "We load the preprocessed product listing dataset from a serialized .pkl file using joblib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product_title</th>\n",
              "      <th>category_label</th>\n",
              "      <th>num_words</th>\n",
              "      <th>num_chars</th>\n",
              "      <th>has_digits_or_special</th>\n",
              "      <th>has_uppercase_terms</th>\n",
              "      <th>longest_word_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>apple iphone 8 plus 64gb silver</td>\n",
              "      <td>mobile phones</td>\n",
              "      <td>6</td>\n",
              "      <td>31</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>apple iphone 8 plus 64 gb spacegrau</td>\n",
              "      <td>mobile phones</td>\n",
              "      <td>7</td>\n",
              "      <td>35</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>apple mq8n2b/a iphone 8 plus 64gb 5.5 12mp sim...</td>\n",
              "      <td>mobile phones</td>\n",
              "      <td>13</td>\n",
              "      <td>70</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>apple iphone 8 plus 64gb space grey</td>\n",
              "      <td>mobile phones</td>\n",
              "      <td>7</td>\n",
              "      <td>35</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>apple iphone 8 plus gold 5.5 64gb 4g unlocked ...</td>\n",
              "      <td>mobile phones</td>\n",
              "      <td>11</td>\n",
              "      <td>54</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       product_title category_label  \\\n",
              "0                    apple iphone 8 plus 64gb silver  mobile phones   \n",
              "1                apple iphone 8 plus 64 gb spacegrau  mobile phones   \n",
              "2  apple mq8n2b/a iphone 8 plus 64gb 5.5 12mp sim...  mobile phones   \n",
              "3                apple iphone 8 plus 64gb space grey  mobile phones   \n",
              "4  apple iphone 8 plus gold 5.5 64gb 4g unlocked ...  mobile phones   \n",
              "\n",
              "   num_words  num_chars  has_digits_or_special  has_uppercase_terms  \\\n",
              "0          6         31                      1                    1   \n",
              "1          7         35                      1                    1   \n",
              "2         13         70                      1                    1   \n",
              "3          7         35                      1                    1   \n",
              "4         11         54                      1                    1   \n",
              "\n",
              "   longest_word_len  \n",
              "0                 6  \n",
              "1                 9  \n",
              "2                10  \n",
              "3                 6  \n",
              "4                 8  "
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import joblib\n",
        "\n",
        "df = joblib.load(\"../data/final_product_data.pkl\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚úÇÔ∏è 2. Train/Test Split\n",
        "\n",
        "Split the cleaned dataset into training and testing sets using stratified sampling to preserve class distribution. This ensures fair evaluation across all product categories."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "category_label\n",
            "fridge freezers     11130\n",
            "mobile phones        4023\n",
            "washing machines     3971\n",
            "cpus                 3792\n",
            "tvs                  3502\n",
            "dishwashers          3374\n",
            "digital cameras      2661\n",
            "microwaves           2307\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "print(df['category_label'].value_counts())\n",
        "\n",
        "\n",
        "X = df[['product_title', 'num_words', 'num_chars', 'has_digits_or_special', 'has_uppercase_terms', 'longest_word_len']]\n",
        "    \n",
        "y = df['category_label'].astype(str)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üßº 3. Preprocessing\n",
        "\n",
        "We prepare the input features using a modular preprocessing pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                       product_title category_label  \\\n",
            "0                    apple iphone 8 plus 64gb silver  mobile phones   \n",
            "1                apple iphone 8 plus 64 gb spacegrau  mobile phones   \n",
            "2  apple mq8n2b/a iphone 8 plus 64gb 5.5 12mp sim...  mobile phones   \n",
            "3                apple iphone 8 plus 64gb space grey  mobile phones   \n",
            "4  apple iphone 8 plus gold 5.5 64gb 4g unlocked ...  mobile phones   \n",
            "\n",
            "   num_words  num_chars  has_digits_or_special  has_uppercase_terms  \\\n",
            "0          6         31                      1                    1   \n",
            "1          7         35                      1                    1   \n",
            "2         13         70                      1                    1   \n",
            "3          7         35                      1                    1   \n",
            "4         11         54                      1                    1   \n",
            "\n",
            "   longest_word_len  \n",
            "0                 6  \n",
            "1                 9  \n",
            "2                10  \n",
            "3                 6  \n",
            "4                 8  \n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# We use MinMaxScaler instead of StandardScaler because:\n",
        "# - MultinomialNB requires non-negative inputs\n",
        "# - MinMaxScaler maps all numeric features into [0,1], preserving non-negativity\n",
        "# - StandardScaler would introduce negative values, causing errors\n",
        "\n",
        "\n",
        "print(df.head(5))\n",
        "preprocess = ColumnTransformer([\n",
        "    ('title', TfidfVectorizer(), 'product_title'),\n",
        "    ('length', MinMaxScaler(), [\n",
        "        \"longest_word_len\",\n",
        "        \"num_words\",\n",
        "        \"num_chars\"\n",
        "    ]),\n",
        "    ('binary', MinMaxScaler(), [\n",
        "        \"has_digits_or_special\",\n",
        "        \"has_uppercase_terms\"\n",
        "    ]),\n",
        "])\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üì¶ 4. Candidate Models\n",
        "\n",
        "We define a set of candidate classification models to evaluate performance across different algorithmic approaches.\n",
        "All models are wrapped in a pipeline that includes preprocessing (TF-IDF + optional scaling) and classification.  \n",
        "This modular setup allows us to benchmark each model consistently across both feature configurations (`product_title` only vs `product_title` + numeric features)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Define candidate models\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=5000),\n",
        "    \"Naive Bayes\": MultinomialNB(),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(),\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"Support Vector Machine\": LinearSVC(max_iter=5000)\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä 5. Training, Prediction, Evaluation\n",
        "\n",
        "We train and evaluate each candidate model using a consistent pipeline:\n",
        "- Each model is wrapped in a `Pipeline` that includes:\n",
        "  - **Preprocessing**: TF-IDF vectorization (and optional MinMax scaling if numeric features are used)\n",
        "  - **Classifier**: one of the selected models\n",
        "\n",
        "üîÅ For each model:\n",
        "- We **fit** the pipeline on the training set (`X_train`, `y_train`)\n",
        "- We **predict** on the test set (`X_test`)\n",
        "- We generate a **classification report** showing precision, recall, and F1-score per class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Logistic Regression ===\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "            cpus       1.00      1.00      1.00       759\n",
            " digital cameras       1.00      0.99      1.00       532\n",
            "     dishwashers       0.97      0.92      0.95       675\n",
            " fridge freezers       0.95      0.99      0.97      2226\n",
            "      microwaves       1.00      0.94      0.97       461\n",
            "   mobile phones       0.99      0.99      0.99       805\n",
            "             tvs       0.98      0.97      0.98       700\n",
            "washing machines       0.98      0.94      0.96       794\n",
            "\n",
            "        accuracy                           0.97      6952\n",
            "       macro avg       0.98      0.97      0.97      6952\n",
            "    weighted avg       0.97      0.97      0.97      6952\n",
            "\n",
            "\n",
            "=== Naive Bayes ===\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "            cpus       1.00      1.00      1.00       759\n",
            " digital cameras       1.00      0.98      0.99       532\n",
            "     dishwashers       0.99      0.85      0.91       675\n",
            " fridge freezers       0.88      1.00      0.94      2226\n",
            "      microwaves       1.00      0.82      0.90       461\n",
            "   mobile phones       0.99      0.98      0.99       805\n",
            "             tvs       0.99      0.97      0.98       700\n",
            "washing machines       1.00      0.90      0.95       794\n",
            "\n",
            "        accuracy                           0.96      6952\n",
            "       macro avg       0.98      0.94      0.96      6952\n",
            "    weighted avg       0.96      0.96      0.96      6952\n",
            "\n",
            "\n",
            "=== Decision Tree ===\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "            cpus       0.99      0.99      0.99       759\n",
            " digital cameras       0.98      0.97      0.98       532\n",
            "     dishwashers       0.95      0.95      0.95       675\n",
            " fridge freezers       0.96      0.98      0.97      2226\n",
            "      microwaves       0.98      0.94      0.96       461\n",
            "   mobile phones       0.95      0.97      0.96       805\n",
            "             tvs       0.99      0.97      0.98       700\n",
            "washing machines       0.96      0.94      0.95       794\n",
            "\n",
            "        accuracy                           0.97      6952\n",
            "       macro avg       0.97      0.96      0.97      6952\n",
            "    weighted avg       0.97      0.97      0.97      6952\n",
            "\n",
            "\n",
            "=== Random Forest ===\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "            cpus       1.00      1.00      1.00       759\n",
            " digital cameras       1.00      0.98      0.99       532\n",
            "     dishwashers       0.96      0.95      0.96       675\n",
            " fridge freezers       0.97      0.99      0.98      2226\n",
            "      microwaves       0.98      0.96      0.97       461\n",
            "   mobile phones       0.98      0.99      0.99       805\n",
            "             tvs       0.99      0.99      0.99       700\n",
            "washing machines       0.97      0.94      0.95       794\n",
            "\n",
            "        accuracy                           0.98      6952\n",
            "       macro avg       0.98      0.97      0.98      6952\n",
            "    weighted avg       0.98      0.98      0.98      6952\n",
            "\n",
            "\n",
            "=== Support Vector Machine ===\n",
            "                  precision    recall  f1-score   support\n",
            "\n",
            "            cpus       1.00      1.00      1.00       759\n",
            " digital cameras       1.00      1.00      1.00       532\n",
            "     dishwashers       0.97      0.93      0.95       675\n",
            " fridge freezers       0.96      0.99      0.98      2226\n",
            "      microwaves       0.99      0.96      0.97       461\n",
            "   mobile phones       0.99      0.99      0.99       805\n",
            "             tvs       0.98      0.99      0.99       700\n",
            "washing machines       0.99      0.94      0.96       794\n",
            "\n",
            "        accuracy                           0.98      6952\n",
            "       macro avg       0.99      0.97      0.98      6952\n",
            "    weighted avg       0.98      0.98      0.98      6952\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for name, model in models.items():\n",
        "    print(f\"\\n=== {name} ===\")\n",
        "    \n",
        "    pipeline = Pipeline([\n",
        "        (\"preprocessing\", preprocess),\n",
        "        (\"classifier\", model)\n",
        "    ])\n",
        "    \n",
        "    # Train\n",
        "    pipeline.fit(X_train, y_train)\n",
        "    \n",
        "    # Predict\n",
        "    y_pred = pipeline.predict(X_test)\n",
        "    \n",
        "    # Classification report\n",
        "    print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üèÜ 6. Select the Best Model\n",
        "\n",
        "In this step, we evaluate all trained models (Logistic Regression, Naive Bayes, Decision Tree, Random Forest, and Support Vector Machine) using key performance metrics:\n",
        "\n",
        "- **Accuracy** ‚Äì overall proportion of correct predictions  \n",
        "- **Macro Avg. F1 Score** ‚Äì harmonic mean of precision and recall, treating all classes equally  \n",
        "- **Weighted Avg. F1 Score** ‚Äì harmonic mean of precision and recall, weighted by class support  \n",
        "\n",
        "### Results (`product_title` + Engineered Features)\n",
        "\n",
        "| Model                  | Accuracy | Macro Avg. F1 | Weighted Avg. F1 | Comments                                                   |\n",
        "|------------------------|----------|----------------|------------------|------------------------------------------------------------|\n",
        "| Logistic Regression     | 0.97     | 0.97           | 0.97             | Very consistent across all classes; strong balance overall |\n",
        "| Naive Bayes             | 0.96     | 0.96           | 0.96             | Good, but weaker on dishwashers and microwaves             |\n",
        "| Decision Tree           | 0.97     | 0.97           | 0.97             | Solid, interpretable, but slightly less stable across categories |\n",
        "| Random Forest           | 0.98     | 0.98           | 0.98             | Strong ensemble, robust across categories                  |\n",
        "| **Support Vector Machine** | **0.98** | **0.98**     | **0.98**         | üèÜ Best overall ‚Äî highest accuracy & balanced across classes |\n",
        "\n",
        "### Why Choose SVC Instead of Random Forest?\n",
        "\n",
        "Both **Random Forest** and **Support Vector Machine (SVC)** achieved excellent performance (‚âà0.98 accuracy). However, we select **SVC** as the final production model for the following reasons:\n",
        "\n",
        "### üîç Performance Balance\n",
        "- **SVC** shows slightly higher **macro F1 (0.99 vs 0.98)**, meaning it balances precision and recall more evenly across all categories.\n",
        "- Random Forest is strong overall, but SVC edges ahead in categories like *digital cameras* and *microwaves*, where recall and precision are perfectly aligned.\n",
        "\n",
        "### üìå Final Decision\n",
        "\n",
        "After comparing all models, we select:\n",
        "\n",
        "- ‚úÖ **Best Model:** Support Vector Machine (SVM)  \n",
        "- üìà Using both **`product_title` (TF‚ÄëIDF)** and **engineered features** (numeric + binary) yields the strongest, most balanced performance.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNIbaCXv0ZUOVuAQAVXzp8M",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
